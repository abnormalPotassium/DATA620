{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c12c568",
   "metadata": {},
   "source": [
    "## Project 3\n",
    "Al Haque, Taha Ahmad\n",
    "\n",
    "\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python,\n",
    "and any features you can think of, build the best name gender classifier you can. For this part, we will essentially re-use code from the textbook and create simple features to improve the gender classifier. We will utilize Naive Bayes and Decision Tree Classifier to make our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "51dca6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb979dbe",
   "metadata": {},
   "source": [
    "The first step is to decide what features of the input are relevant and how to encode those features, we will first use the gender_features function from the textbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b76563aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the function\n",
    "\n",
    "def gender_feature(word):\n",
    "    return{'first letter': word[0].lower()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "17d9eeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first letter': 'f'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check as an example.\n",
    "gender_feature('Fiona')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7250be",
   "metadata": {},
   "source": [
    "Extracts the male and females name from both texts and puts them in a dictionary format (Taken from the textbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "08908e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "## Extracts the male and females name from both texts and puts them in a dictionary format\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "[(name, 'female') for name in names.words('female.txt')])\n",
    "import random\n",
    "# Set a random seed to prevent the names from being shuffled every time we called it\n",
    "random.seed(543)\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3300dd9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Here the names are randomized\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m head(labeled_names)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'head' is not defined"
     ]
    }
   ],
   "source": [
    "# Here the names are randomized\n",
    "# Check the formation of labeled_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7d54506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create the train,dev_test,and test_set\n",
    "# Training set is used to train the model,and the dev-test set is used to perform error analysis, the test is\n",
    "# used to evaluate of the system\n",
    "train_names = labeled_names[1000:]\n",
    "devtest_names = labeled_names[500:1000]\n",
    "test_names = labeled_names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "336ef0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is of the dev-test is: 0.616\n",
      "The accuracy is of the dev-test is: 0.616\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_feature(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(gender_feature(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(gender_feature(n), gender) for (n, gender) in test_names]\n",
    "# Here we call the Naive Bayes Classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "dtclassifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "print(f'The accuracy is of the dev-test is: {nltk.classify.accuracy(classifier, devtest_set)}')\n",
    "print(f'The accuracy is of the dev-test is: {nltk.classify.accuracy(dtclassifier, devtest_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724887db",
   "metadata": {},
   "source": [
    "Creating a simple feature such as plucking the first letter from each word gives us a 62% accuracy in determining the gender of a person,let's add more features onto our gender_feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "864eb075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            first letter = 'w'              male : female =      5.1 : 1.0\n",
      "            first letter = 'u'              male : female =      2.8 : 1.0\n",
      "            first letter = 'q'              male : female =      2.7 : 1.0\n",
      "            first letter = 'x'              male : female =      2.3 : 1.0\n",
      "            first letter = 'k'            female : male   =      2.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "47dd5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add the last letter feature and see if the last letter of a person's name can determine their gender\n",
    "def gender_feature2(word):\n",
    "    return{'first letter': word[0].lower(),\n",
    "          'last letter':word[-1].lower()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0d324bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is of the dev-test is: 0.774\n",
      "The accuracy is of the dev-test is: 0.778\n"
     ]
    }
   ],
   "source": [
    "train_set2 = [(gender_feature2(n), gender) for (n, gender) in train_names]\n",
    "devtest_set2 = [(gender_feature2(n), gender) for (n, gender) in devtest_names]\n",
    "test_set2 = [(gender_feature2(n), gender) for (n, gender) in test_names]\n",
    "# Here we call the Naive Bayes Classifier again and decision Tree\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set2)\n",
    "dtclassifier2 = nltk.DecisionTreeClassifier.train(train_set2)\n",
    "print(f'The accuracy is of the dev-test is: {nltk.classify.accuracy(classifier2, devtest_set2)}')\n",
    "print(f'The accuracy is of the dev-test is: {nltk.classify.accuracy(dtclassifier2, devtest_set2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56066355",
   "metadata": {},
   "source": [
    "Here we have improved the accuracy of the dev-test up to 78% percent which is not surprising since the textbook also tested this feature,let's test one more feature which is the length of the name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "eb375e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last letter = 'a'            female : male   =     31.9 : 1.0\n",
      "             last letter = 'k'              male : female =     31.1 : 1.0\n",
      "             last letter = 'v'              male : female =     17.7 : 1.0\n",
      "             last letter = 'f'              male : female =     17.5 : 1.0\n",
      "             last letter = 'p'              male : female =     12.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier2.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b11840ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the length of a name into the dictionary attributes\n",
    "def gender_feature3(word):\n",
    "    return{'first letter': word[0].lower(),\n",
    "          'last letter':word[-1].lower(),\n",
    "          'length' : len(word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "08bf289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is of the dev-test is: 0.776\n",
      "The accuracy is of the dev-test is: 0.768\n"
     ]
    }
   ],
   "source": [
    "train_set3 = [(gender_feature3(n), gender) for (n, gender) in train_names]\n",
    "devtest_set3 = [(gender_feature3(n), gender) for (n, gender) in devtest_names]\n",
    "test_set3 = [(gender_feature3(n), gender) for (n, gender) in test_names]\n",
    "# Here we call the Naive Bayes Classifier again\n",
    "classifier3 = nltk.NaiveBayesClassifier.train(train_set3)\n",
    "dtclassifier3 = nltk.DecisionTreeClassifier.train(train_set3)\n",
    "print(f'The accuracy is of the dev-test is: {nltk.classify.accuracy(classifier3, devtest_set3)}')\n",
    "print(f'The accuracy is of the dev-test is: {nltk.classify.accuracy(dtclassifier3, devtest_set3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dc8e7476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the test set using Naive Bayes is: 0.792\n",
      "The accuracy of the test set using Decision Tree is: 0.76\n"
     ]
    }
   ],
   "source": [
    "## Let's test this classifier on our test-set\n",
    "print(f'The accuracy of the test set using Naive Bayes is: {nltk.classify.accuracy(classifier3, test_set3)}')\n",
    "print(f'The accuracy of the test set using Decision Tree is: {nltk.classify.accuracy(dtclassifier3, test_set3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b9bdd6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last letter = 'a'            female : male   =     31.9 : 1.0\n",
      "             last letter = 'k'              male : female =     31.1 : 1.0\n",
      "             last letter = 'v'              male : female =     17.7 : 1.0\n",
      "             last letter = 'f'              male : female =     17.5 : 1.0\n",
      "             last letter = 'p'              male : female =     12.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "## It seems the length wasn't even considered at all\n",
    "classifier3.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba033068",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "At the moment it seems like features such as the length of a person's name and the first letter of a person's name only made tiny incremental improvement into predicting the gender of a person's name, but ultimately they were only slight increases. For Naive Bayes it was able to generalize better onto the test set compared to the decision tree classifier but it was only a slight increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b3df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
